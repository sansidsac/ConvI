# ============================================================
# ConvI — Environment Variables (copy to .env and fill in)
# ============================================================

APP_NAME="ConvI — Conversation Intelligence API"
APP_VERSION="0.1.0"
DEBUG=false

# PostgreSQL
DATABASE_URL=postgresql://convi_user:password@localhost:5432/convi

# FAISS index directory
FAISS_INDEX_PATH=data/faiss_index

# Whisper model size (tiny | base | small | medium | large-v3)
WHISPER_MODEL_SIZE=large-v3

# spaCy model
SPACY_MODEL=en_core_web_sm

# Speech Pipeline
# HuggingFace token — needed for pyannote gated diarization model.
# Get yours at https://hf.co/pyannote/speaker-diarization-3.1
# Without this, diarization falls back to single-speaker mode.
PYANNOTE_AUTH_TOKEN=
# Force number of speakers (e.g. 2 for agent+customer). Leave empty for auto.
DIARIZATION_NUM_SPEAKERS=2
# Emotion model (SpeechBrain HuggingFace hub id)
EMOTION_MODEL=speechbrain/emotion-recognition-wav2vec2-IEMOCAP
# Supported audio languages (comma-separated ISO-639-1 codes)
SUPPORTED_AUDIO_LANGUAGES=["en","ml"]

# Embedding model
EMBEDDING_MODEL=BAAI/bge-m3

# Local LLM model (HuggingFace path or local directory)
LLM_MODEL_PATH=Qwen/Qwen2.5-7B-Instruct
LLM_MAX_NEW_TOKENS=1024
